{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49bf500b-af57-4fc7-96f0-94ab2d217360",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 150\u001b[0m\n\u001b[1;32m    147\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 117\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# text = completion['choices'][0]['message']['content']\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m text_new \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m polly_client \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    120\u001b[0m s3_client \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from contextlib import closing\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from tempfile import gettempdir\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import openai\n",
    "import json \n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "bucket_name = 'aigc-bj-team2'\n",
    "\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "q = \"Please help me continue the story, the background is a little girl in the forest, separated by paragraphs\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer.\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "        # {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "def en_text_to_speech(input_text, polly_client, s3_client, index):\n",
    "    try:\n",
    "        # Request speech synthesis\n",
    "        response = polly_client.synthesize_speech(Text=input_text, OutputFormat=\"mp3\",\n",
    "                                            VoiceId=\"Joanna\")\n",
    "    except (BotoCoreError, ClientError) as error:\n",
    "        # The service returned an error, exit gracefully\n",
    "        print(error)\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    # Access the audio stream from the response\n",
    "    if \"AudioStream\" in response:\n",
    "        # Note: Closing the stream is important because the service throttles on the\n",
    "        # number of parallel connections. Here we are using contextlib.closing to\n",
    "        # ensure the close method of the stream object will be called automatically\n",
    "        # at the end of the with statement's scope.\n",
    "        with closing(response[\"AudioStream\"]) as stream:\n",
    "            output = os.path.join(gettempdir(), str(index) + \"_speech.mp3\")\n",
    "\n",
    "            try:\n",
    "                # Open a file for writing the output as a binary stream\n",
    "                with open(output, \"wb\") as file:\n",
    "                    file.write(stream.read())\n",
    "                    print(\"Written to %s\" % output)\n",
    "                    s3_client.upload_file(output, bucket_name, \"speech-en.mp3\")\n",
    "                    # download audio file from s3 \n",
    "                    subprocess.call([\"aws\", \"s3\", \"cp\", \"s3://aigc-bj-team2/speech-en.mp3\", \"audio/\"+str(index) + \"_speech-en.mp3\"])\n",
    "            except IOError as error:\n",
    "                # Could not write to file, exit gracefully\n",
    "                print(error)\n",
    "                sys.exit(-1)\n",
    "    else:\n",
    "        # The response didn't contain audio data, exit gracefully\n",
    "        print(\"Could not stream audio\")\n",
    "        sys.exit(-1)\n",
    "\n",
    "def cn_text_to_speech(input_text, polly_client, s3_client, index):\n",
    "    try:\n",
    "        # Request speech synthesis\n",
    "        response = polly_client.synthesize_speech(Text=input_text, OutputFormat=\"mp3\",\n",
    "                                            VoiceId=\"Zhiyu\")\n",
    "    except (BotoCoreError, ClientError) as error:\n",
    "        # The service returned an error, exit gracefully\n",
    "        print(error)\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    # Access the audio stream from the response\n",
    "    if \"AudioStream\" in response:\n",
    "        # Note: Closing the stream is important because the service throttles on the\n",
    "        # number of parallel connections. Here we are using contextlib.closing to\n",
    "        # ensure the close method of the stream object will be called automatically\n",
    "        # at the end of the with statement's scope.\n",
    "        with closing(response[\"AudioStream\"]) as stream:\n",
    "            output = os.path.join(gettempdir(), str(index) + \"_speech.mp3\")\n",
    "\n",
    "            try:\n",
    "                # Open a file for writing the output as a binary stream\n",
    "                with open(output, \"wb\") as file:\n",
    "                    file.write(stream.read())\n",
    "                                        \n",
    "                    print(\"Written to %s\" % output)\n",
    "                    s3_client.upload_file(output, bucket_name, \"speech-cn.mp3\")\n",
    "                    # download audio file from s3 \n",
    "                    subprocess.call([\"aws\", \"s3\", \"cp\", \"s3://aigc-bj-team2/speech-cn.mp3\", \"audio/\"+str(index) + \"_speech-cn.mp3\"])\n",
    "                    \n",
    "            except IOError as error:\n",
    "                # Could not write to file, exit gracefully\n",
    "                print(error)\n",
    "                sys.exit(-1)\n",
    "    else:\n",
    "        # The response didn't contain audio data, exit gracefully\n",
    "        print(\"Could not stream audio\")\n",
    "        sys.exit(-1)\n",
    "        \n",
    "def main():\n",
    "    global text\n",
    "    \n",
    "    count = 0\n",
    "    # text = completion['choices'][0]['message']['content']\n",
    "    text_new = text.split(\"\\n\")\n",
    "    \n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    for txt in tqdm(text_new):\n",
    "        if txt == \"\":\n",
    "            continue    \n",
    "\n",
    "        # en_input_text = txt\n",
    "        q = txt\n",
    "        \n",
    "        translate = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an excellent translator who can help me translate the recognized text and support automatic detection and mutual translation of Chinese and English content\"},\n",
    "                {\"role\": \"user\", \"content\": q}\n",
    "                # {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "                # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "                # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        cn_input_text = translate['choices'][0]['message']['content']\n",
    "        print(cn_input_text)\n",
    "                \n",
    "        # en_text_to_speech(en_input_text, polly_client, s3_client, count)\n",
    "        # count += 1\n",
    "\n",
    "        cn_text_to_speech(cn_input_text, polly_client, s3_client, count)\n",
    "        count += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83335898-3123-45d0-9979-0f6686be7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install moviepy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24a2ce7a-44c2-44b7-89f1-f9f0bccce104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI界面\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from contextlib import closing\n",
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import threading\n",
    "from tempfile import gettempdir\n",
    "from IPython.display import Audio\n",
    "import openai\n",
    "import json \n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import *\n",
    "import time\n",
    "\n",
    "bucket_name = 'aigc-bj-team2'\n",
    "\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "q = \"Please help me continue the story, the background is a little girl in the forest, separated by paragraphs\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer.\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "        # {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 准备一个预先准备好的 MP4 视频文件路径\n",
    "mp4_file_path = \"output_video.mp4\"\n",
    "\n",
    "# use CHATGPT generate a story\n",
    "def generate_story(input_text):\n",
    "    \n",
    "    q = input_text\n",
    "    translate = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"将输入内容翻译成英文\"},\n",
    "            {\"role\": \"user\", \"content\": q}\n",
    "                ]\n",
    "            )\n",
    "    new_text = translate['choices'][0]['message']['content']\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer. Starting with the content I input, generate a short fairy tale story within 80 words\"},\n",
    "        {\"role\": \"user\", \"content\": new_text}\n",
    "        ]\n",
    "    )\n",
    "    return completion['choices'][0]['message']['content']\n",
    "    \n",
    "    \n",
    "def cn_text_to_speech(input_text, polly_client, s3_client, index):\n",
    "    try:\n",
    "        # Request speech synthesis\n",
    "        response = polly_client.synthesize_speech(Text=input_text, OutputFormat=\"mp3\",\n",
    "                                            VoiceId=\"Zhiyu\")\n",
    "    except (BotoCoreError, ClientError) as error:\n",
    "        # The service returned an error, exit gracefully\n",
    "        print(error)\n",
    "        sys.exit(-1)\n",
    "    # Access the audio stream from the response\n",
    "    if \"AudioStream\" in response:\n",
    "        # Note: Closing the stream is important because the service throttles on the\n",
    "        # number of parallel connections. Here we are using contextlib.closing to\n",
    "        # ensure the close method of the stream object will be called automatically\n",
    "        # at the end of the with statement's scope.\n",
    "        with closing(response[\"AudioStream\"]) as stream:\n",
    "            output = os.path.join(gettempdir(), str(index) + \"_speech.mp3\")\n",
    "            try:\n",
    "                # Open a file for writing the output as a binary stream\n",
    "                with open(output, \"wb\") as file:\n",
    "                    file.write(stream.read())\n",
    "                                        \n",
    "                    print(\"Written to %s\" % output)\n",
    "                    s3_client.upload_file(output, bucket_name, \"speech-cn.mp3\")\n",
    "                    # download audio file from s3 \n",
    "                    subprocess.call([\"aws\", \"s3\", \"cp\", \"s3://aigc-bj-team2/speech-cn.mp3\", \"audio/\"+str(index) + \"_speech-cn.mp3\"])\n",
    "            except IOError as error:\n",
    "                # Could not write to file, exit gracefully\n",
    "                print(error)\n",
    "                sys.exit(-1)\n",
    "    else:\n",
    "        # The response didn't contain audio data, exit gracefully\n",
    "        print(\"Could not stream audio\")\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    \n",
    "def generate_audio(story_text):\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    count = 0\n",
    "    text_new = story_text.split(\".\")\n",
    "    \n",
    "    for txt in tqdm(text_new):\n",
    "        if txt == \"\":\n",
    "            continue    \n",
    "        q = txt\n",
    "        translate = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Translate input content into Chinese\"},\n",
    "                {\"role\": \"user\", \"content\": q}\n",
    "                    ]\n",
    "                )\n",
    "        cn_input_text = translate['choices'][0]['message']['content']\n",
    "        print(cn_input_text)\n",
    "        cn_text_to_speech(cn_input_text, polly_client, s3_client, count)\n",
    "        count += 1\n",
    "\n",
    "txt2img_url = r'http://127.0.0.1:7860/sdapi/v1/txt2img'\n",
    "\n",
    "def submit_post(url: str, data: dict):\n",
    "    return requests.post(url, data=json.dumps(data))\n",
    "\n",
    "\n",
    "def save_encoded_image(b64_image: str, output_path: str):\n",
    "    with open(output_path, 'wb') as image_file:\n",
    "        image_file.write(base64.b64decode(b64_image))\n",
    "\n",
    "def generate_image(story_text):\n",
    "    data = {'prompt': ' ',\n",
    "            'negative_prompt': 'poorly drawn face, incongruous colors and deformed body',\n",
    "            'sampler_index': 'DPM++ SDE',\n",
    "            'seed': 1234,\n",
    "            'steps': 20,\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'cfg_scale': 8}\n",
    "    cnt = 0\n",
    "    text_res = []\n",
    "    text = story_text.split(\".\")\n",
    "    for txt in tqdm(text):\n",
    "        if txt==\"\":\n",
    "            continue\n",
    "        data['prompt'] = \"lora:flower_field_10k:1.1 hypernet:forest_5k:0.8, style of painting:1.0, beautiful figures:\" + txt\n",
    "        # data['prompt'] = \"lora:cutescrap05v_cutescrap3.safetensors, style of painting, beautiful figures:\" + txt\n",
    "        text_res.append(txt)\n",
    "        response = submit_post(txt2img_url, data)\n",
    "        save_image_path = r'img/tmp_'+str(cnt)+'.png'\n",
    "        save_encoded_image(response.json()['images'][0], save_image_path)\n",
    "        cnt+=1\n",
    "    \n",
    "def generate_video():\n",
    "    audio_folder = \"audio\"\n",
    "    image_folder = \"img\"\n",
    "\n",
    "    count = 0\n",
    "    for file in os.listdir(audio_folder) :\n",
    "        if file.endswith(\".mp3\"):\n",
    "            count += 1\n",
    "    \n",
    "    # 获取音频文件列表\n",
    "    audio_paths = [os.path.join(audio_folder, f\"{i}_speech-cn.mp3\") for i in range(count)]\n",
    "\n",
    "    # 获取图片文件列表，保持与音频文件数量一致\n",
    "    image_paths = [os.path.join(image_folder, f\"tmp_{i}.png\") for i in range(count)]\n",
    "    \n",
    "    # 加载音频和图片\n",
    "    audios = [AudioFileClip(audio_path) for audio_path in audio_paths]\n",
    "    images = [ImageClip(image_path).set_duration(audio.duration)\n",
    "              for audio, image_path in zip(audios, image_paths)]\n",
    "\n",
    "\n",
    "    # 设置帧率\n",
    "    fps = 5  # 可以根据需要进行调整\n",
    "\n",
    "    # 合成视频\n",
    "    clips = [CompositeVideoClip([image.set_audio(audio)])\n",
    "             for image, audio in zip(images, audios)]\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "    # 保存视频\n",
    "    final_video.write_videofile(\n",
    "        \"output_video.mp4\", fps=fps)\n",
    "    \n",
    "    folder_path = \"img\"\n",
    "    # 获取文件夹内的文件列表\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # 循环遍历文件列表并删除文件\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            \n",
    "    folder_path = \"audio\"\n",
    "    # 获取文件夹内的文件列表\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # 循环遍历文件列表并删除文件\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    \n",
    "    return \"output_video.mp4\"\n",
    "    \n",
    "\n",
    "def generate_mp4(input_text):\n",
    "    \n",
    "    story_text = generate_story(input_text)\n",
    "    \n",
    "    thread1 = threading.Thread(target=generate_audio, args = (story_text,))\n",
    "    thread2 = threading.Thread(target=generate_image, args = (story_text,))\n",
    "\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    thread1.join() \n",
    "    thread2.join()\n",
    "    \n",
    "    generate_video()\n",
    "    mp4_file_path = \"output_video.mp4\"\n",
    "    SadTalker_file_path = \"./output/SadTalker_result.mp4\"\n",
    "    clip1 = VideoFileClip(mp4_file_path)\n",
    "    size = (int(clip1.size[0]/40.0)*10, int(clip1.size[1]/40.0)*10)\n",
    "    clip2 = VideoFileClip(SadTalker_file_path).resize(\n",
    "        size).set_position((0, clip1.size[1]-size[1])).without_audio()   # 移动到左下角\n",
    "    \n",
    "    target_duration = clip1.duration\n",
    "    repeats = int(target_duration / clip2.duration)\n",
    "    # 重复短视频帧以达到目标时长\n",
    "    long_video = clip2\n",
    "    repeats-=1\n",
    "    mod_time = target_duration % clip2.duration\n",
    "\n",
    "    while repeats:\n",
    "        long_video = concatenate_videoclips([long_video, clip2])\n",
    "        repeats-=1\n",
    "\n",
    "    clip2 = clip2.set_duration(mod_time)\n",
    "    long_video = concatenate_videoclips([long_video, clip2])\n",
    "    \n",
    "    \n",
    "    CompositeVideoClip([clip1, long_video]).write_videofile(r'result.mp4')\n",
    "    mp4_file_path = \"result.mp4\"\n",
    "    # generate_audio(story_text)\n",
    "    # generate_image(story_text)\n",
    "    \n",
    "        \n",
    "    return mp4_file_path\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=generate_mp4,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"video\",\n",
    "    \n",
    "    live=False,  # 实时更新\n",
    "    \n",
    "    title=\"童话大王 Fairy Tale Teller\",\n",
    "    description=\"请输入您需要续写的故事：\",\n",
    "    examples=[\n",
    "        [\"一个小女孩在森林中\"],\n",
    "        [\"一个小男孩在海边\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3964c7-0562-48c2-aeba-7621e6b9431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'audio/0_speech-cn.mp3'\n",
    "Audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df32686-3738-45f9-8208-a4e1c6b91a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0c66d-e153-4672-b6ce-7bb81b96b076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca41ef-13eb-466a-b33f-0c474e7fb02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f172e4-b798-423a-adef-1c6012b7609f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd3c298-2aec-4cdf-8f3b-e9200abc7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.23.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.19.3)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.4.7)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install moviepy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2696726-0b41-400a-acf8-5a083c204a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7881\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://6ff858f5d27c4c7b90.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6ff858f5d27c4c7b90.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# UI界面\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from contextlib import closing\n",
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import threading\n",
    "from tempfile import gettempdir\n",
    "from IPython.display import Audio\n",
    "import openai\n",
    "import json \n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import *\n",
    "import time\n",
    "\n",
    "bucket_name = 'aigc-bj-team2'\n",
    "\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "q = \"Please help me continue the story, the background is a little girl in the forest, separated by paragraphs\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer.\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "        # {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 准备一个预先准备好的 MP4 视频文件路径\n",
    "mp4_file_path = \"output_video.mp4\"\n",
    "SadTalker_output_file = \"./output/SadTalker_result.mp4\"\n",
    "\n",
    "\n",
    "\n",
    "# use CHATGPT generate a story\n",
    "def generate_story(input_text):\n",
    "    \n",
    "    q = input_text\n",
    "    translate = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"将输入内容翻译成英文\"},\n",
    "            {\"role\": \"user\", \"content\": q}\n",
    "                ]\n",
    "            )\n",
    "    new_text = translate['choices'][0]['message']['content']\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer. Starting with the content I input, generate a short fairy tale story within 80 words\"},\n",
    "        {\"role\": \"user\", \"content\": new_text}\n",
    "        ]\n",
    "    )\n",
    "    return completion['choices'][0]['message']['content']\n",
    "    \n",
    "    \n",
    "def cn_text_to_speech(input_text, polly_client, s3_client, index,output_dir):\n",
    "    try:\n",
    "        # Request speech synthesis\n",
    "        response = polly_client.synthesize_speech(Text=input_text, OutputFormat=\"mp3\",\n",
    "                                            VoiceId=\"Zhiyu\")\n",
    "    except (BotoCoreError, ClientError) as error:\n",
    "        # The service returned an error, exit gracefully\n",
    "        print(error)\n",
    "        sys.exit(-1)\n",
    "    # Access the audio stream from the response\n",
    "    if \"AudioStream\" in response:\n",
    "        # Note: Closing the stream is important because the service throttles on the\n",
    "        # number of parallel connections. Here we are using contextlib.closing to\n",
    "        # ensure the close method of the stream object will be called automatically\n",
    "        # at the end of the with statement's scope.\n",
    "        with closing(response[\"AudioStream\"]) as stream:\n",
    "            output = os.path.join(gettempdir(), str(index) + \"_speech.mp3\")\n",
    "            try:\n",
    "                # Open a file for writing the output as a binary stream\n",
    "                with open(output, \"wb\") as file:\n",
    "                    file.write(stream.read())\n",
    "                                        \n",
    "                    print(\"Written to %s\" % output)\n",
    "                    s3_client.upload_file(output, bucket_name, \"speech-cn.mp3\")\n",
    "                    # download audio file from s3 \n",
    "                    subprocess.call([\"aws\", \"s3\", \"cp\", \"s3://aigc-bj-team2/speech-cn.mp3\",output_dir+str(index) + \"_speech-cn.mp3\"])\n",
    "            except IOError as error:\n",
    "                # Could not write to file, exit gracefully\n",
    "                print(error)\n",
    "                sys.exit(-1)\n",
    "    else:\n",
    "        # The response didn't contain audio data, exit gracefully\n",
    "        print(\"Could not stream audio\")\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    \n",
    "def generate_audio(story_text):\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    tmp_all_sentences = \"\"\n",
    "    count = 0\n",
    "    text_new = story_text.split(\".\")\n",
    "    \n",
    "    for txt in tqdm(text_new):\n",
    "        if txt == \"\":\n",
    "            continue    \n",
    "        q = txt\n",
    "        translate = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Translate input content into Chinese\"},\n",
    "                {\"role\": \"user\", \"content\": q}\n",
    "                    ]\n",
    "                )\n",
    "        cn_input_text = translate['choices'][0]['message']['content']\n",
    "        print(cn_input_text)\n",
    "        tmp_all_sentences = tmp_all_sentences+cn_input_text\n",
    "        \n",
    "        cn_text_to_speech(cn_input_text, polly_client, s3_client, count,\"audio/\")\n",
    "        count += 1\n",
    "        \n",
    "    file_handle=open('all_cn_sentences.txt',mode='w')\n",
    "    file_handle.write(tmp_all_sentences)\n",
    "    file_handle.close()\n",
    "        \n",
    "txt2img_url = r'http://127.0.0.1:7860/sdapi/v1/txt2img'\n",
    "\n",
    "def submit_post(url: str, data: dict):\n",
    "    return requests.post(url, data=json.dumps(data))\n",
    "\n",
    "\n",
    "def save_encoded_image(b64_image: str, output_path: str):\n",
    "    with open(output_path, 'wb') as image_file:\n",
    "        image_file.write(base64.b64decode(b64_image))\n",
    "\n",
    "def generate_image(story_text):\n",
    "    data = {'prompt': ' ',\n",
    "            'negative_prompt': 'poorly drawn face, incongruous colors and deformed body',\n",
    "            'sampler_index': 'DPM++ SDE',\n",
    "            'seed': 1234,\n",
    "            'steps': 20,\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'cfg_scale': 8}\n",
    "    cnt = 0\n",
    "    text_res = []\n",
    "    text = story_text.split(\".\")\n",
    "    for txt in tqdm(text):\n",
    "        if txt==\"\":\n",
    "            continue\n",
    "        data['prompt'] = \"lora:flower_field_10k:1.1 hypernet:forest_5k:0.8, style of painting:1.0, beautiful figures:\" + txt\n",
    "        # data['prompt'] = \"lora:cutescrap05v_cutescrap3.safetensors, style of painting, beautiful figures:\" + txt\n",
    "        text_res.append(txt)\n",
    "        response = submit_post(txt2img_url, data)\n",
    "        save_image_path = r'img/tmp_'+str(cnt)+'.png'\n",
    "        save_encoded_image(response.json()['images'][0], save_image_path)\n",
    "        cnt+=1\n",
    "    \n",
    "def generate_video():\n",
    "    audio_folder = \"audio\"\n",
    "    image_folder = \"img\"\n",
    "\n",
    "    count = 0\n",
    "    for file in os.listdir(audio_folder) :\n",
    "        if file.endswith(\".mp3\"):\n",
    "            count += 1\n",
    "    \n",
    "    # 获取音频文件列表\n",
    "    audio_paths = [os.path.join(audio_folder, f\"{i}_speech-cn.mp3\") for i in range(count)]\n",
    "\n",
    "    # 获取图片文件列表，保持与音频文件数量一致\n",
    "    image_paths = [os.path.join(image_folder, f\"tmp_{i}.png\") for i in range(count)]\n",
    "    \n",
    "    # 加载音频和图片\n",
    "    audios = [AudioFileClip(audio_path) for audio_path in audio_paths]\n",
    "    images = [ImageClip(image_path).set_duration(audio.duration)\n",
    "              for audio, image_path in zip(audios, image_paths)]\n",
    "\n",
    "\n",
    "    # 设置帧率\n",
    "    fps = 5  # 可以根据需要进行调整\n",
    "\n",
    "    # 合成视频\n",
    "    clips = [CompositeVideoClip([image.set_audio(audio)])\n",
    "             for image, audio in zip(images, audios)]\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "    # 保存视频\n",
    "    final_video.write_videofile(\n",
    "        \"output_video.mp4\", fps=fps)\n",
    "    \n",
    "    folder_path = \"img\"\n",
    "    # 获取文件夹内的文件列表\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # 循环遍历文件列表并删除文件\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            \n",
    "    folder_path = \"audio\"\n",
    "    # 获取文件夹内的文件列表\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # 循环遍历文件列表并删除文件\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    \n",
    "    return \"output_video.mp4\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def generate_sadtalk():\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    f = open('all_cn_sentences.txt')\n",
    "    cn_all_sentences = f.readlines()\n",
    "    cn_all_sentences = cn_all_sentences[0]\n",
    "    count = 100\n",
    "    print(\"\\n cn_all_sentences : \",cn_all_sentences)\n",
    "    cn_text_to_speech(cn_all_sentences, polly_client, s3_client, count,\"\")\n",
    "    \n",
    "    subprocess.call(['python', 'inference.py',\n",
    "          '--driven_audio', '100_speech-cn.mp3' ,\n",
    "           '--source_image','girl.png',\n",
    "           '--result_dir', './output'])\n",
    "    print('return st_file: ',SadTalker_output_file)\n",
    "    return SadTalker_output_file\n",
    "\n",
    "\n",
    "\n",
    "def generate_mp4(input_text):\n",
    "    \n",
    "    story_text = generate_story(input_text)\n",
    "    \n",
    "    thread1 = threading.Thread(target=generate_audio, args = (story_text,))\n",
    "    thread2 = threading.Thread(target=generate_image, args = (story_text,))\n",
    "\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    thread1.join() \n",
    "    thread2.join()\n",
    "    \n",
    "    generate_video()\n",
    "    print(\"finish story video generation\")\n",
    "    generate_sadtalk()\n",
    "    print(\"finish sadtalker video generation\")\n",
    "    mp4_file_path = \"output_video.mp4\"\n",
    "    SadTalker_file_path = \"./output/SadTalker_result.mp4\"\n",
    "    clip1 = VideoFileClip(mp4_file_path)\n",
    "    size = (int(clip1.size[0]/40.0)*10, int(clip1.size[1]/40.0)*10)\n",
    "    clip2 = VideoFileClip(SadTalker_file_path).resize(\n",
    "        size).set_position((0, clip1.size[1]-size[1])).without_audio()   # 移动到左下角\n",
    "    \n",
    "    clip2.set_duration(clip1.duration)\n",
    "#     target_duration = clip1.duration\n",
    "#     repeats = int(target_duration / clip2.duration)\n",
    "#     # 重复短视频帧以达到目标时长\n",
    "#     long_video = clip2\n",
    "#     if repeats>0: repeats-=1\n",
    "#     mod_time = target_duration % clip2.duration\n",
    "\n",
    "#     while repeats:\n",
    "#         long_video = concatenate_videoclips([long_video, clip2])\n",
    "#         repeats-=1\n",
    "   \n",
    "#     clip2 = clip2.set_duration(mod_time)\n",
    "#     long_video = concatenate_videoclips([long_video, clip2])\n",
    "    \n",
    "    # CompositeVideoClip([clip1, long_video]).write_videofile(r'result.mp4')\n",
    "    \n",
    "    CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4')\n",
    "    mp4_file_path = \"result.mp4\"\n",
    "    # generate_audio(story_text)\n",
    "    # generate_image(story_text)\n",
    "    \n",
    "        \n",
    "    return mp4_file_path\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=generate_mp4,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"video\",\n",
    "    \n",
    "    live=False,  # 实时更新\n",
    "    \n",
    "    title=\"童话大王 Fairy Tale Teller\",\n",
    "    description=\"请输入您需要续写的故事：\",\n",
    "    examples=[\n",
    "        [\"一个小女孩在森林中\"],\n",
    "        [\"一个小男孩在海边\"],\n",
    "        [\"在一个古老的王国里\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c800e8c-98f3-403e-92aa-ceed72e9515c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c512a-1407-41a8-8218-f1bd09d79878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc7740-0f6c-419f-9cc9-09def9cda49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782e255-8c64-4f21-8b19-f503d389363e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbd7da-8bb5-42bd-bbbd-d1b0348da2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd802f6a-362e-4d67-9a64-42005e649ec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 16] Device or resource busy: 'audio/.nfsac877566b860c02400000043'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path):\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: 'audio/.nfsac877566b860c02400000043'"
     ]
    }
   ],
   "source": [
    "folder_path = \"img\"\n",
    "\n",
    "# 获取文件夹内的文件列表\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# 循环遍历文件列表并删除文件\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "        \n",
    "folder_path = \"audio\"\n",
    "\n",
    "# 获取文件夹内的文件列表\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# 循环遍历文件列表并删除文件\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e6e224e-e65a-4813-8839-aa0b4d510829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在与爱丽丝共处的时光里，小女孩学到了许多智慧和善良。她帮助森林中的小动物找到食物，修复受伤的翅膀，并与它们分享欢乐和忧伤。\n"
     ]
    }
   ],
   "source": [
    "q = \"In her time with Alice, the little girl learned a great deal of wisdom and kindness. She helped the small animals in the forest find food, mend injured wings, and shared joy and sorrow with them.\"\n",
    "translate = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Translate input content into Chinese\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "        ]\n",
    "        )\n",
    "new_text = translate['choices'][0]['message']['content']\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7230427b-da84-4284-bc1c-4e7a3cb15657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5.0\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f94d538-5de6-45d0-ab06-039c6a4d7974",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'long_video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m clip2 \u001b[38;5;241m=\u001b[39m VideoFileClip(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mresize(size)\u001b[38;5;241m.\u001b[39mset_position((\u001b[38;5;241m0\u001b[39m, clip1\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m size[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;66;03m# 移动到左下角\u001b[39;00m\n\u001b[1;32m     12\u001b[0m repeats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(target_duration \u001b[38;5;241m/\u001b[39m clip2\u001b[38;5;241m.\u001b[39mduration)\n\u001b[0;32m---> 14\u001b[0m CompositeVideoClip([clip1, \u001b[43mlong_video\u001b[49m])\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'long_video' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "##合并故事视频和SadTalker视频\n",
    "clip1 = VideoFileClip(r\"output_video.mp4\")\n",
    "small_window_scale = 0.35  # 调整小窗的比例，可以根据需要进行调整\n",
    "\n",
    "target_duration = clip1.duration\n",
    "\n",
    "\n",
    "size = (int(clip1.size[0] * small_window_scale), int(clip1.size[1] * small_window_scale))\n",
    "clip2 = VideoFileClip(r\"output_video.mp4\").resize(size).set_position((0, clip1.size[1] - size[1])) # 移动到左下角\n",
    "repeats = int(target_duration / clip2.duration)\n",
    "\n",
    "CompositeVideoClip([clip1, long_video]).write_videofile(r'result.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a143257-9855-4893-952b-54e547a5b8d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m clip1 \u001b[38;5;241m=\u001b[39m VideoFileClip(mp4_file_path)\n\u001b[1;32m      5\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(clip1\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m40.0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mint\u001b[39m(clip1\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m40.0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m clip2 \u001b[38;5;241m=\u001b[39m VideoFileClip(mp4_file_path)\u001b[38;5;241m.\u001b[39mresize(\n\u001b[0;32m----> 7\u001b[0m     size, method\u001b[38;5;241m=\u001b[39m\u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mResampling\u001b[38;5;241m.\u001b[39mLANCZOS)\u001b[38;5;241m.\u001b[39mset_position((\u001b[38;5;241m0\u001b[39m, clip1\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39msize[\u001b[38;5;241m1\u001b[39m]))  \u001b[38;5;66;03m# 指定 method 参数\u001b[39;00m\n\u001b[1;32m      8\u001b[0m CompositeVideoClip([clip1, clip2])\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_position((\u001b[38;5;241m0\u001b[39m, clip1\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39msize[\u001b[38;5;241m1\u001b[39m]))  \u001b[38;5;66;03m# 指定 method 参数\u001b[39;00m\n\u001b[1;32m      9\u001b[0m CompositeVideoClip([clip1, clip2])\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "mp4_file_path = r\"output_video.mp4\"\n",
    "clip1 = VideoFileClip(mp4_file_path)\n",
    "size = (int(clip1.size[0]/40.0)*10, int(clip1.size[1]/40.0)*10)\n",
    "clip2 = VideoFileClip(mp4_file_path).resize(\n",
    "    size, method=Image.Resampling.LANCZOS).set_position((0, clip1.size[1]-size[1]))  # 指定 method 参数\n",
    "CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4').set_position((0, clip1.size[1]-size[1]))  # 指定 method 参数\n",
    "CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ae389a-9e52-407a-a075-a8babc76b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video result.mp4.\n",
      "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video result.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready result.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "mp4_file_path = r\"output_video.mp4\"\n",
    "clip1 = VideoFileClip(mp4_file_path)\n",
    "size = (int(clip1.size[0]/40.0)*10, int(clip1.size[1]/40.0)*10)\n",
    "clip2 = VideoFileClip(mp4_file_path).resize(\n",
    "    size).set_position((0, clip1.size[1]-size[1]))  # 指定 method 参数\n",
    "# CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4').set_position((0, clip1.size[1]-size[1]))  # 指定 method 参数\n",
    "CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95028070-576a-4c6b-990f-df147ea20270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9648ce-1d8b-49f9-b137-93a16f2d7931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474a811-848e-4f2f-97d1-eead6bf0cea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e79f4-ed3b-48f9-b208-753f363dac3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa5a19ca-9c00-4efd-bbde-b07e68a7dc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7882\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://c52810537a7e6f7eab.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c52810537a7e6f7eab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 尝试放弃图片视频的音频，只用sadtalker的音频\n",
    "# UI界面\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from contextlib import closing\n",
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import threading\n",
    "from tempfile import gettempdir\n",
    "from IPython.display import Audio\n",
    "import openai\n",
    "import json \n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import *\n",
    "import time\n",
    "\n",
    "bucket_name = 'aigc-bj-team2'\n",
    "\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "q = \"Please help me continue the story, the background is a little girl in the forest, separated by paragraphs\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer.\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "        # {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 准备一个预先准备好的 MP4 视频文件路径\n",
    "mp4_file_path = \"output_video.mp4\"\n",
    "SadTalker_output_file = \"./output/SadTalker_result.mp4\"\n",
    "\n",
    "\n",
    "\n",
    "# use CHATGPT generate a story\n",
    "def generate_story(input_text):\n",
    "    \n",
    "    q = input_text\n",
    "    translate = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"将输入内容翻译成英文\"},\n",
    "            {\"role\": \"user\", \"content\": q}\n",
    "                ]\n",
    "            )\n",
    "    new_text = translate['choices'][0]['message']['content']\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer. Starting with the content I input, generate a short fairy tale story within 80 words\"},\n",
    "        {\"role\": \"user\", \"content\": new_text}\n",
    "        ]\n",
    "    )\n",
    "    return completion['choices'][0]['message']['content']\n",
    "    \n",
    "    \n",
    "def cn_text_to_speech(input_text, polly_client, s3_client, index,output_dir):\n",
    "    try:\n",
    "        # Request speech synthesis\n",
    "        response = polly_client.synthesize_speech(Text=input_text, OutputFormat=\"mp3\",\n",
    "                                            VoiceId=\"Zhiyu\")\n",
    "    except (BotoCoreError, ClientError) as error:\n",
    "        # The service returned an error, exit gracefully\n",
    "        print(error)\n",
    "        sys.exit(-1)\n",
    "    # Access the audio stream from the response\n",
    "    if \"AudioStream\" in response:\n",
    "        # Note: Closing the stream is important because the service throttles on the\n",
    "        # number of parallel connections. Here we are using contextlib.closing to\n",
    "        # ensure the close method of the stream object will be called automatically\n",
    "        # at the end of the with statement's scope.\n",
    "        with closing(response[\"AudioStream\"]) as stream:\n",
    "            output = os.path.join(gettempdir(), str(index) + \"_speech.mp3\")\n",
    "            try:\n",
    "                # Open a file for writing the output as a binary stream\n",
    "                with open(output, \"wb\") as file:\n",
    "                    file.write(stream.read())\n",
    "                                        \n",
    "                    print(\"Written to %s\" % output)\n",
    "                    s3_client.upload_file(output, bucket_name, \"speech-cn.mp3\")\n",
    "                    # download audio file from s3 \n",
    "                    subprocess.call([\"aws\", \"s3\", \"cp\", \"s3://aigc-bj-team2/speech-cn.mp3\",output_dir+str(index) + \"_speech-cn.mp3\"])\n",
    "            except IOError as error:\n",
    "                # Could not write to file, exit gracefully\n",
    "                print(error)\n",
    "                sys.exit(-1)\n",
    "    else:\n",
    "        # The response didn't contain audio data, exit gracefully\n",
    "        print(\"Could not stream audio\")\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    \n",
    "def generate_audio(story_text):\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    tmp_all_sentences = \"\"\n",
    "    count = 0\n",
    "    text_new = story_text.split(\".\")\n",
    "    \n",
    "    for txt in tqdm(text_new):\n",
    "        if txt == \"\":\n",
    "            continue    \n",
    "        q = txt\n",
    "        translate = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Translate input content into Chinese\"},\n",
    "                {\"role\": \"user\", \"content\": q}\n",
    "                    ]\n",
    "                )\n",
    "        cn_input_text = translate['choices'][0]['message']['content']\n",
    "        print(cn_input_text)\n",
    "        tmp_all_sentences = tmp_all_sentences+cn_input_text\n",
    "        \n",
    "        cn_text_to_speech(cn_input_text, polly_client, s3_client, count,\"audio/\")\n",
    "        count += 1\n",
    "        \n",
    "    file_handle=open('all_cn_sentences.txt',mode='w')\n",
    "    file_handle.write(tmp_all_sentences)\n",
    "    file_handle.close()\n",
    "        \n",
    "txt2img_url = r'http://127.0.0.1:7860/sdapi/v1/txt2img'\n",
    "\n",
    "def submit_post(url: str, data: dict):\n",
    "    return requests.post(url, data=json.dumps(data))\n",
    "\n",
    "\n",
    "def save_encoded_image(b64_image: str, output_path: str):\n",
    "    with open(output_path, 'wb') as image_file:\n",
    "        image_file.write(base64.b64decode(b64_image))\n",
    "\n",
    "def generate_image(story_text):\n",
    "    data = {'prompt': ' ',\n",
    "            'negative_prompt': 'poorly drawn face, incongruous colors and deformed body',\n",
    "            'sampler_index': 'DPM++ SDE',\n",
    "            'seed': 1234,\n",
    "            'steps': 20,\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'cfg_scale': 8}\n",
    "    cnt = 0\n",
    "    text_res = []\n",
    "    text = story_text.split(\".\")\n",
    "    for txt in tqdm(text):\n",
    "        if txt==\"\":\n",
    "            continue\n",
    "        data['prompt'] = \"lora:flower_field_10k:1.1 hypernet:forest_5k:0.8, style of painting:1.0, beautiful figures:\" + txt\n",
    "        # data['prompt'] = \"lora:cutescrap05v_cutescrap3.safetensors, style of painting, beautiful figures:\" + txt\n",
    "        text_res.append(txt)\n",
    "        response = submit_post(txt2img_url, data)\n",
    "        save_image_path = r'img/tmp_'+str(cnt)+'.png'\n",
    "        save_encoded_image(response.json()['images'][0], save_image_path)\n",
    "        cnt+=1\n",
    "    \n",
    "def generate_video():\n",
    "    audio_folder = \"audio\"\n",
    "    image_folder = \"img\"\n",
    "\n",
    "    count = 0\n",
    "    for file in os.listdir(audio_folder) :\n",
    "        if file.endswith(\".mp3\"):\n",
    "            count += 1\n",
    "    \n",
    "    # 获取音频文件列表\n",
    "    audio_paths = [os.path.join(audio_folder, f\"{i}_speech-cn.mp3\") for i in range(count)]\n",
    "\n",
    "    # 获取图片文件列表，保持与音频文件数量一致\n",
    "    image_paths = [os.path.join(image_folder, f\"tmp_{i}.png\") for i in range(count)]\n",
    "    \n",
    "    # 加载音频和图片\n",
    "    audios = [AudioFileClip(audio_path) for audio_path in audio_paths]\n",
    "    images = [ImageClip(image_path).set_duration(audio.duration)\n",
    "              for audio, image_path in zip(audios, image_paths)]\n",
    "\n",
    "\n",
    "    # 设置帧率\n",
    "    fps = 5  # 可以根据需要进行调整\n",
    "\n",
    "    # 合成视频\n",
    "    # clips = [CompositeVideoClip([image.set_audio(audio)])\n",
    "    #          for image, audio in zip(images, audios)]\n",
    "    clips = [CompositeVideoClip([image])\n",
    "             for image in images]\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "    # 保存视频\n",
    "    final_video.write_videofile(\n",
    "        \"output_video.mp4\", fps=fps)\n",
    "    \n",
    "        # 循环遍历文件列表并删除文件\n",
    "    for filename in audio_paths:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "    # 循环遍历文件列表并删除文件\n",
    "    for filename in image_paths:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "    \n",
    "    return \"output_video.mp4\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def generate_sadtalk():\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    f = open('all_cn_sentences.txt')\n",
    "    cn_all_sentences = f.readlines()\n",
    "    cn_all_sentences = cn_all_sentences[0]\n",
    "    count = 100\n",
    "    print(\"\\n cn_all_sentences : \",cn_all_sentences)\n",
    "    cn_text_to_speech(cn_all_sentences, polly_client, s3_client, count,\"\")\n",
    "    \n",
    "    subprocess.call(['python', 'inference.py',\n",
    "          '--driven_audio', '100_speech-cn.mp3' ,\n",
    "           '--source_image','girl.png',\n",
    "           '--result_dir', './output'])\n",
    "    print('return st_file: ',SadTalker_output_file)\n",
    "    return SadTalker_output_file\n",
    "\n",
    "\n",
    "\n",
    "def generate_mp4(input_text):\n",
    "    \n",
    "    story_text = generate_story(input_text)\n",
    "    \n",
    "    thread1 = threading.Thread(target=generate_audio, args = (story_text,))\n",
    "    thread2 = threading.Thread(target=generate_image, args = (story_text,))\n",
    "\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    thread1.join() \n",
    "    thread2.join()\n",
    "    \n",
    "    generate_video()\n",
    "    print(\"finish story video generation\")\n",
    "    generate_sadtalk()\n",
    "    print(\"finish sadtalker video generation\")\n",
    "    mp4_file_path = \"output_video.mp4\"\n",
    "    SadTalker_file_path = \"./output/SadTalker_result.mp4\"\n",
    "    clip1 = VideoFileClip(mp4_file_path)\n",
    "    size = (int(clip1.size[0]/40.0)*10, int(clip1.size[1]/40.0)*10)\n",
    "    clip2 = VideoFileClip(SadTalker_file_path).resize(\n",
    "        size).set_position((0, clip1.size[1]-size[1]))#.without_audio()   # 移动到左下角\n",
    "    \n",
    "    clip2.set_duration(clip1.duration)\n",
    "#     target_duration = clip1.duration\n",
    "#     repeats = int(target_duration / clip2.duration)\n",
    "#     # 重复短视频帧以达到目标时长\n",
    "#     long_video = clip2\n",
    "#     if repeats>0: repeats-=1\n",
    "#     mod_time = target_duration % clip2.duration\n",
    "\n",
    "#     while repeats:\n",
    "#         long_video = concatenate_videoclips([long_video, clip2])\n",
    "#         repeats-=1\n",
    "   \n",
    "#     clip2 = clip2.set_duration(mod_time)\n",
    "#     long_video = concatenate_videoclips([long_video, clip2])\n",
    "    \n",
    "    # CompositeVideoClip([clip1, long_video]).write_videofile(r'result.mp4')\n",
    "    \n",
    "    CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4')\n",
    "    mp4_file_path = \"result.mp4\"\n",
    "    # generate_audio(story_text)\n",
    "    # generate_image(story_text)\n",
    "    \n",
    "        \n",
    "    return mp4_file_path\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=generate_mp4,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"video\",\n",
    "    \n",
    "    live=False,  # 实时更新\n",
    "    title=\"童话大王 Fairy Tale Teller\",\n",
    "    description=\"请输入您需要续写的故事：\",\n",
    "    examples=[\n",
    "        [\"一个小女孩在森林中\"],\n",
    "        [\"一个小男孩在海边\"],\n",
    "        [\"在一个古老的王国里\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b500ea94-d6ba-4058-88a5-f5270cbffd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7881\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://c301f96df08f71e3b4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c301f96df08f71e3b4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 11:22\n",
    "## 尝试放弃图片视频的音频，只用sadtalker的音频\n",
    "# UI界面\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from contextlib import closing\n",
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import threading\n",
    "from tempfile import gettempdir\n",
    "from IPython.display import Audio\n",
    "import openai\n",
    "import json \n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import *\n",
    "import time\n",
    "\n",
    "bucket_name = 'aigc-bj-team2'\n",
    "\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "q = \"Please help me continue the story, the background is a little girl in the forest, separated by paragraphs\"\n",
    "\n",
    "story_type = {\n",
    "    \"美好童话\": \"You are an imaginative fairy tale writer.\",\n",
    "    \"恐怖故事\": \"Create a chilling and suspenseful horror story.\",\n",
    "    \"冷笑话\": \"Provide me with a dry and witty joke and its answer\"\n",
    "}\n",
    "\n",
    "image_type = {\n",
    "    \"美好童话\": \"lora:flower_field_10k:1.1 hypernet:forest_5k:0.8, style of painting:1.0, beautiful figures:\",\n",
    "    \"恐怖故事\": \"Suspenseful horror, chilling\",\n",
    "    \"冷笑话\": \"Funny scene\"\n",
    "}\n",
    "\n",
    "story_length = {\n",
    "    \"短\": \"generate a short fairy tale story within 50 words\",\n",
    "    \"中\": \"generate a short fairy tale story within 100 words\",\n",
    "    \"长\": \"generate a short fairy tale story within 150 words\"\n",
    "}\n",
    "\n",
    "story_age = {\n",
    "    \"小孩\": \"You are an imaginative fairy tale writer.\",\n",
    "    \"成年人\": \"Create a chilling and suspenseful horror story.\",\n",
    "    \"老年人\": \"Generate a witty and light-hearted cold joke for me\"\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "[\"一个小女孩在森林中\", \"美好童话\", \"短\", \"小孩\"],\n",
    "        [\"一个小男孩在海边\", \"美好童话\", \"中\", \"小孩\"],\n",
    "        [\"在一个古老的王国里\", \"恐怖故事\", \"短\", \"成年人\"]\n",
    "'''\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an imaginative fairy tale writer.\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "        # {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 准备一个预先准备好的 MP4 视频文件路径\n",
    "mp4_file_path = \"output_video.mp4\"\n",
    "SadTalker_output_file = \"./output/SadTalker_result.mp4\"\n",
    "\n",
    "\n",
    "\n",
    "# use CHATGPT generate a story\n",
    "def generate_story(input_text, mode, length):\n",
    "    \n",
    "    q = input_text\n",
    "    translate = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"将输入内容翻译成英文\"},\n",
    "            {\"role\": \"user\", \"content\": q}\n",
    "                ]\n",
    "            )\n",
    "    new_text = translate['choices'][0]['message']['content']\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": story_type[mode] + \"Starting with the content I input,\" + story_length[length]},\n",
    "        {\"role\": \"user\", \"content\": new_text}\n",
    "        ]\n",
    "    )\n",
    "    return completion['choices'][0]['message']['content']\n",
    "    \n",
    "    \n",
    "def cn_text_to_speech(input_text, polly_client, s3_client, index,output_dir):\n",
    "    try:\n",
    "        # Request speech synthesis\n",
    "        response = polly_client.synthesize_speech(Text=input_text, OutputFormat=\"mp3\",\n",
    "                                            VoiceId=\"Zhiyu\")\n",
    "    except (BotoCoreError, ClientError) as error:\n",
    "        # The service returned an error, exit gracefully\n",
    "        print(error)\n",
    "        sys.exit(-1)\n",
    "    # Access the audio stream from the response\n",
    "    if \"AudioStream\" in response:\n",
    "        # Note: Closing the stream is important because the service throttles on the\n",
    "        # number of parallel connections. Here we are using contextlib.closing to\n",
    "        # ensure the close method of the stream object will be called automatically\n",
    "        # at the end of the with statement's scope.\n",
    "        with closing(response[\"AudioStream\"]) as stream:\n",
    "            output = os.path.join(gettempdir(), str(index) + \"_speech.mp3\")\n",
    "            try:\n",
    "                # Open a file for writing the output as a binary stream\n",
    "                with open(output, \"wb\") as file:\n",
    "                    file.write(stream.read())\n",
    "                                        \n",
    "                    print(\"Written to %s\" % output)\n",
    "                    s3_client.upload_file(output, bucket_name, \"speech-cn.mp3\")\n",
    "                    # download audio file from s3 \n",
    "                    subprocess.call([\"aws\", \"s3\", \"cp\", \"s3://aigc-bj-team2/speech-cn.mp3\",output_dir+str(index) + \"_speech-cn.mp3\"])\n",
    "            except IOError as error:\n",
    "                # Could not write to file, exit gracefully\n",
    "                print(error)\n",
    "                sys.exit(-1)\n",
    "    else:\n",
    "        # The response didn't contain audio data, exit gracefully\n",
    "        print(\"Could not stream audio\")\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    \n",
    "def generate_audio(story_text):\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    tmp_all_sentences = \"\"\n",
    "    count = 0\n",
    "    text_new = story_text.split(\".\")\n",
    "    \n",
    "    for txt in tqdm(text_new):\n",
    "        if txt == \"\":\n",
    "            continue    \n",
    "        q = txt\n",
    "        translate = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Translate input content into Chinese\"},\n",
    "                {\"role\": \"user\", \"content\": q}\n",
    "                    ]\n",
    "                )\n",
    "        cn_input_text = translate['choices'][0]['message']['content']\n",
    "        print(cn_input_text)\n",
    "        tmp_all_sentences = tmp_all_sentences+cn_input_text\n",
    "        \n",
    "        cn_text_to_speech(cn_input_text, polly_client, s3_client, count,\"audio/\")\n",
    "        count += 1\n",
    "        \n",
    "    file_handle=open('all_cn_sentences.txt',mode='w')\n",
    "    file_handle.write(tmp_all_sentences)\n",
    "    file_handle.close()\n",
    "        \n",
    "txt2img_url = r'http://127.0.0.1:7860/sdapi/v1/txt2img'\n",
    "\n",
    "def submit_post(url: str, data: dict):\n",
    "    return requests.post(url, data=json.dumps(data))\n",
    "\n",
    "\n",
    "def save_encoded_image(b64_image: str, output_path: str):\n",
    "    with open(output_path, 'wb') as image_file:\n",
    "        image_file.write(base64.b64decode(b64_image))\n",
    "\n",
    "def generate_image(story_text, mode, length):\n",
    "    data = {'prompt': ' ',\n",
    "            'negative_prompt': 'poorly drawn face, incongruous colors and deformed body',\n",
    "            'sampler_index': 'DPM++ SDE',\n",
    "            'seed': 1234,\n",
    "            'steps': 20,\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'cfg_scale': 8}\n",
    "    cnt = 0\n",
    "    text_res = []\n",
    "    text = story_text.split(\".\")\n",
    "    for txt in tqdm(text):\n",
    "        if txt==\"\":\n",
    "            continue\n",
    "        data['prompt'] = image_type[mode] + txt\n",
    "        # data['prompt'] = \"lora:cutescrap05v_cutescrap3.safetensors, style of painting, beautiful figures:\" + txt\n",
    "        text_res.append(txt)\n",
    "        response = submit_post(txt2img_url, data)\n",
    "        save_image_path = r'img/tmp_'+str(cnt)+'.png'\n",
    "        save_encoded_image(response.json()['images'][0], save_image_path)\n",
    "        cnt+=1\n",
    "    \n",
    "def generate_video():\n",
    "    audio_folder = \"audio\"\n",
    "    image_folder = \"img\"\n",
    "\n",
    "    count = 0\n",
    "    for file in os.listdir(audio_folder) :\n",
    "        if file.endswith(\".mp3\"):\n",
    "            count += 1\n",
    "    \n",
    "    # 获取音频文件列表\n",
    "    audio_paths = [os.path.join(audio_folder, f\"{i}_speech-cn.mp3\") for i in range(count)]\n",
    "\n",
    "    # 获取图片文件列表，保持与音频文件数量一致\n",
    "    image_paths = [os.path.join(image_folder, f\"tmp_{i}.png\") for i in range(count)]\n",
    "    \n",
    "    # 加载音频和图片\n",
    "    audios = [AudioFileClip(audio_path) for audio_path in audio_paths]\n",
    "    images = [ImageClip(image_path).set_duration(audio.duration)\n",
    "              for audio, image_path in zip(audios, image_paths)]\n",
    "\n",
    "\n",
    "    # 设置帧率\n",
    "    fps = 5  # 可以根据需要进行调整\n",
    "\n",
    "    # 合成视频\n",
    "    # clips = [CompositeVideoClip([image.set_audio(audio)])\n",
    "    #          for image, audio in zip(images, audios)]\n",
    "    clips = [CompositeVideoClip([image])\n",
    "             for image in images]\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "    # 保存视频\n",
    "    final_video.write_videofile(\n",
    "        \"output_video.mp4\", fps=fps)\n",
    "    \n",
    "        # 循环遍历文件列表并删除文件\n",
    "    for filename in audio_paths:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "    # 循环遍历文件列表并删除文件\n",
    "    for filename in image_paths:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "    \n",
    "    return \"output_video.mp4\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def generate_sadtalk():\n",
    "    polly_client = boto3.client('polly')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    \n",
    "    f = open('all_cn_sentences.txt')\n",
    "    cn_all_sentences = f.readlines()\n",
    "    cn_all_sentences = cn_all_sentences[0]\n",
    "    count = 100\n",
    "    print(\"\\n cn_all_sentences : \",cn_all_sentences)\n",
    "    cn_text_to_speech(cn_all_sentences, polly_client, s3_client, count,\"\")\n",
    "    \n",
    "    subprocess.call(['python', 'inference.py',\n",
    "          '--driven_audio', '100_speech-cn.mp3' ,\n",
    "           '--source_image','girl.png',\n",
    "           '--result_dir', './output'])\n",
    "    print('return st_file: ',SadTalker_output_file)\n",
    "    return SadTalker_output_file\n",
    "\n",
    "\n",
    "\n",
    "def generate_mp4(input_text, mode, length, age):\n",
    "    \n",
    "    \n",
    "    # print(mode)\n",
    "    \n",
    "    story_text = generate_story(input_text, mode, length)\n",
    "    \n",
    "    thread1 = threading.Thread(target=generate_audio, args = (story_text,))\n",
    "    thread2 = threading.Thread(target=generate_image, args = (story_text, mode, length, ))\n",
    "\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    thread1.join() \n",
    "    thread2.join()\n",
    "    \n",
    "    generate_video()\n",
    "    print(\"finish story video generation\")\n",
    "    generate_sadtalk()\n",
    "    print(\"finish sadtalker video generation\")\n",
    "    mp4_file_path = \"output_video.mp4\"\n",
    "    SadTalker_file_path = \"./output/SadTalker_result.mp4\"\n",
    "    clip1 = VideoFileClip(mp4_file_path)\n",
    "    size = (int(clip1.size[0]/40.0)*10, int(clip1.size[1]/40.0)*10)\n",
    "    clip2 = VideoFileClip(SadTalker_file_path).resize(\n",
    "        size).set_position((0, clip1.size[1]-size[1]))#.without_audio()   # 移动到左下角\n",
    "    \n",
    "    clip2.set_duration(clip1.duration)\n",
    "#     target_duration = clip1.duration\n",
    "#     repeats = int(target_duration / clip2.duration)\n",
    "#     # 重复短视频帧以达到目标时长\n",
    "#     long_video = clip2\n",
    "#     if repeats>0: repeats-=1\n",
    "#     mod_time = target_duration % clip2.duration\n",
    "\n",
    "#     while repeats:\n",
    "#         long_video = concatenate_videoclips([long_video, clip2])\n",
    "#         repeats-=1\n",
    "   \n",
    "#     clip2 = clip2.set_duration(mod_time)\n",
    "#     long_video = concatenate_videoclips([long_video, clip2])\n",
    "    \n",
    "    # CompositeVideoClip([clip1, long_video]).write_videofile(r'result.mp4')\n",
    "    \n",
    "    CompositeVideoClip([clip1, clip2]).write_videofile(r'result.mp4')\n",
    "    mp4_file_path = \"result.mp4\"\n",
    "    # generate_audio(story_text)\n",
    "    # generate_image(story_text)\n",
    "    \n",
    "        \n",
    "    return mp4_file_path\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=generate_mp4,\n",
    "    inputs=[\n",
    "        \"text\",\n",
    "        gr.Radio([\"美好童话\", \"恐怖故事\", \"冷笑话\"], label=\"故事类型\",\n",
    "                 info=\"选择故事类型\"),\n",
    "        gr.Radio([\"短\", \"中\", \"长\"], label=\"故事时长\",\n",
    "                 info=\"选择故事时长\"),\n",
    "        gr.Radio([\"小孩\", \"成年人\", \"老年人\"], label=\"您的年龄\",\n",
    "                 info=\"选择您的年龄\"),\n",
    "    ],\n",
    "    outputs=\"video\",\n",
    "\n",
    "    live=False,  # 实时更新\n",
    "\n",
    "    title=\"故事大王 StoryGen\",\n",
    "    description=\"请输入您需要续写的故事：\",\n",
    "    examples=[\n",
    "        [\"一个小女孩在森林中\", \"美好童话\", \"短\", \"小孩\"],\n",
    "        [\"一个小男孩在海边\", \"美好童话\", \"中\", \"小孩\"],\n",
    "        [\"在一个古老的王国里\", \"恐怖故事\", \"短\", \"成年人\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452868aa-fed6-414a-a0bc-c50956605d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "audio_folder = \"audio\"\n",
    "image_folder = \"img\"\n",
    "\n",
    "count = 0\n",
    "for file in os.listdir(audio_folder) :\n",
    "    if file.endswith(\".mp3\"):\n",
    "        count += 1\n",
    "\n",
    "# 获取音频文件列表\n",
    "audio_paths = [os.path.join(audio_folder, f\"{i}_speech-cn.mp3\") for i in range(count)]\n",
    "\n",
    "# 循环遍历文件列表并删除文件\n",
    "for filename in audio_paths:\n",
    "    if os.path.isfile(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067668c1-49cd-4187-ad0d-d3fa8a0ef028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
